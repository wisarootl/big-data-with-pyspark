{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark: SparkSession = SparkSession.builder.appName(\"ExampleApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"data/2017_StPaul_MN_Real_Estate.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+--------------------+---------------+-----+\n",
      "|StreetNumberNumeric|FirePlaces|   LotSizeDimensions|       ListType|Acres|\n",
      "+-------------------+----------+--------------------+---------------+-----+\n",
      "|              11511|         0|             279X200|Exclusive Right| 1.28|\n",
      "|              11200|         0|             100x140|Exclusive Right| 0.32|\n",
      "|               8583|         0|             120x296|Exclusive Right|0.822|\n",
      "|               9350|         1|             208X208|Exclusive Right| 0.94|\n",
      "|               2915|         1|             116x200|Exclusive Right|  0.0|\n",
      "|               3604|         1|              50x150|Exclusive Right|0.172|\n",
      "|               9957|         0|              common|Exclusive Right| 0.05|\n",
      "|               9934|         0|              common|Exclusive Right| 0.05|\n",
      "|               9926|         0|              common|Exclusive Right| 0.05|\n",
      "|               9928|         0|              common|Exclusive Right| 0.05|\n",
      "|               9902|         0|              common|Exclusive Right| 0.05|\n",
      "|               9904|         0|              common|Exclusive Right| 0.05|\n",
      "|               9894|         0|              common|Exclusive Right| 0.05|\n",
      "|               9892|         0|              COMMON|Exclusive Right| 0.05|\n",
      "|               9295|         1|261 x 293 x 287 x...|Exclusive Right|1.661|\n",
      "|               9930|         0|               36X32|Exclusive Right| 0.05|\n",
      "|               9898|         0|               36X32|Exclusive Right| 0.05|\n",
      "|               9924|         0|              COMMON|Exclusive Right| 0.05|\n",
      "|               9906|         0|              COMMON|Exclusive Right| 0.05|\n",
      "|               9938|         0|              COMMON|Exclusive Right| 0.05|\n",
      "+-------------------+----------+--------------------+---------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.select([\"StreetNumberNumeric\", \"FirePlaces\", \"LotSizeDimensions\", \"ListType\", \"Acres\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['STREETNUMBERNUMERIC', 'LOTSIZEDIMENSIONS']\n",
    "df = df.drop(*cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+-----+\n",
      "|FirePlaces|       ListType|Acres|\n",
      "+----------+---------------+-----+\n",
      "|         0|Exclusive Right| 1.28|\n",
      "|         0|Exclusive Right| 0.32|\n",
      "|         0|Exclusive Right|0.822|\n",
      "|         1|Exclusive Right| 0.94|\n",
      "|         1|Exclusive Right|  0.0|\n",
      "+----------+---------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"data/2017_StPaul_MN_Real_Estate.parquet\")\n",
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|  ASSUMABLEMORTGAGE|\n",
      "+-------------------+\n",
      "|  Yes w/ Qualifying|\n",
      "| Information Coming|\n",
      "|Yes w/No Qualifying|\n",
      "|      Not Assumable|\n",
      "|               NULL|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['ASSUMABLEMORTGAGE']).distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4976\n"
     ]
    }
   ],
   "source": [
    "yes_values = ['Yes w/ Qualifying', 'Yes w/No Qualifying']\n",
    "text_filter = ~df['ASSUMABLEMORTGAGE'].isin(yes_values) | df['ASSUMABLEMORTGAGE'].isNull()\n",
    "df = df.where(text_filter)\n",
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import log\n",
    "df = df.withColumn('log_SalesClosePrice', log(df['SalesClosePrice']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean, stddev\n",
    "\n",
    "\n",
    "mean_val = df.agg({'log_SalesClosePrice': 'mean'}).collect()[0][0]\n",
    "stddev_val = df.agg({'log_SalesClosePrice': 'stddev'}).collect()[0][0]\n",
    "\n",
    "low_bound = mean_val - (3 * stddev_val)\n",
    "hi_bound = mean_val + (3 * stddev_val)\n",
    "\n",
    "# Filter the data to fit between the lower and upper bounds\n",
    "df = df.where((df['log_SalesClosePrice'] < hi_bound) & (df['log_SalesClosePrice'] > low_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4946\n"
     ]
    }
   ],
   "source": [
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big-data-with-pyspark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
