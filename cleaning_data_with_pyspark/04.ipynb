{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"ExampleApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "departures_df = spark.read.csv('data/AA_DFW_2015_Departures_Short.csv.gz', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any duration of 0\n",
    "departures_df = departures_df.filter(departures_df[3] > 0)\n",
    "\n",
    "# Add an ID column\n",
    "departures_df = departures_df.withColumn('id', F.monotonically_increasing_id())\n",
    "\n",
    "# Write the file out to JSON format\n",
    "# departures_df.write.json('.cache/output.json', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the file to a DataFrame and perform a row count\n",
    "# annotations_df = spark.read.csv('annotations.csv.gz', sep='|')\n",
    "# full_count = annotations_df.count()\n",
    "\n",
    "# # Count the number of rows beginning with '#'\n",
    "# comment_count = annotations_df.where(col('_c0').startswith('#')).count()\n",
    "\n",
    "# # Import the file to a new DataFrame, without commented rows\n",
    "# no_comments_df = spark.read.csv('annotations.csv.gz', sep='|', comment='#')\n",
    "\n",
    "# # Count the new DataFrame and verify the difference is as expected\n",
    "# no_comments_count = no_comments_df.count()\n",
    "# print(\"Full count: %d\\nComment count: %d\\nRemaining count: %d\" % (full_count, comment_count, no_comments_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split _c0 on the tab character and store the list in a variable\n",
    "# tmp_fields = F.split(annotations_df['_c0'], '\\t')\n",
    "\n",
    "# # Create the colcount column on the DataFrame\n",
    "# annotations_df = annotations_df.withColumn('colcount', F.size(tmp_fields))\n",
    "\n",
    "# # Remove any rows containing fewer than 5 fields\n",
    "# annotations_df_filtered = annotations_df.filter(~ (annotations_df[\"colcount\"] < 5))\n",
    "\n",
    "# # Count the number of rows\n",
    "# final_count = annotations_df_filtered.count()\n",
    "# print(\"Initial count: %d\\nFinal count: %d\" % (initial_count, final_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split the content of _c0 on the tab character (aka, '\\t')\n",
    "# split_cols = F.split(annotations_df[\"_c0\"], '\\t')\n",
    "\n",
    "# # Add the columns folder, filename, width, and height\n",
    "# split_df = annotations_df.withColumn('folder', split_cols.getItem(0))\n",
    "# split_df = split_df.withColumn('filename', split_cols.getItem(1))\n",
    "# split_df = split_df.withColumn('width', split_cols.getItem(2))\n",
    "# split_df = split_df.withColumn('height', split_cols.getItem(3))\n",
    "\n",
    "# # Add split_cols as a column\n",
    "# split_df = split_df.withColumn('split_cols', split_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def retriever(cols, colcount):\n",
    "#   # Return a list of dog data\n",
    "#   return cols[4:colcount]\n",
    "\n",
    "# # Define the method as a UDF\n",
    "# udfRetriever = F.udf(retriever, ArrayType(StringType()))\n",
    "\n",
    "# # Create a new column using your UDF\n",
    "# split_df = split_df.withColumn('dog_list', udfRetriever(split_df.split_cols, split_df.colcount))\n",
    "\n",
    "# # Remove the original column, split_cols, and the colcount\n",
    "# split_df = split_df.drop('_c0').drop('split_cols').drop('colcount')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Rename the column in valid_folders_df\n",
    "# valid_folders_df = valid_folders_df.withColumnRenamed('_c0', 'folder')\n",
    "\n",
    "# # Count the number of rows in split_df\n",
    "# split_count = split_df.count()\n",
    "\n",
    "# # Join the DataFrames\n",
    "# joined_df = split_df.join(F.broadcast(valid_folders_df), \"folder\")\n",
    "\n",
    "# # Compare the number of rows remaining\n",
    "# joined_count = joined_df.count()\n",
    "# print(\"Before: %d\\nAfter: %d\" % (split_count, joined_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Determine the row counts for each DataFrame\n",
    "# split_count = split_df.count()\n",
    "# joined_count = joined_df.count()\n",
    "\n",
    "# # Create a DataFrame containing the invalid rows\n",
    "# invalid_df = split_df.join(F.broadcast(joined_df), 'folder', 'left_anti')\n",
    "\n",
    "# # Validate the count of the new DataFrame is as expected\n",
    "# invalid_count = invalid_df.count()\n",
    "# print(\" split_df:\\t%d\\n joined_df:\\t%d\\n invalid_df: \\t%d\" % (split_count, joined_count, invalid_count))\n",
    "\n",
    "# # Determine the number of distinct folder rows removed\n",
    "# invalid_folder_count = invalid_df.select('folder').distinct().count()\n",
    "# print(\"%d distinct invalid folders found\" % invalid_folder_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Analysis and Delivery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select the dog details and show 10 untruncated rows\n",
    "# print(joined_df.select('dog_list').show(10, truncate=False))\n",
    "\n",
    "# # Define a schema type for the details in the dog list\n",
    "# DogType = StructType([\n",
    "# \tStructField(\"breed\", StringType(), False),\n",
    "#     StructField(\"start_x\", IntegerType(), False),\n",
    "#     StructField(\"start_y\", IntegerType(), False),\n",
    "#     StructField(\"end_x\", IntegerType(), False),\n",
    "#     StructField(\"end_y\", IntegerType(), False)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a function to return the number and type of dogs as a tuple\n",
    "# def dogParse(doglist):\n",
    "#   dogs = []\n",
    "#   for dog in doglist:\n",
    "#     (breed, start_x, start_y, end_x, end_y) = dog.split(',')\n",
    "#     dogs.append((breed, int(start_x), int(start_y), int(end_x), int(end_y)))\n",
    "#   return dogs\n",
    "\n",
    "# # Create a UDF\n",
    "# udfDogParse = F.udf(dogParse, ArrayType(DogType))\n",
    "\n",
    "\n",
    "# # Use the UDF to list of dogs and drop the old column\n",
    "# joined_df = joined_df.withColumn('dogs', udfDogParse('dog_list')).drop('dog_list')\n",
    "\n",
    "\n",
    "# # Show the number of dogs in the first 10 rows\n",
    "# joined_df.select(F.size('dogs')).show(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a UDF to determine the number of pixels per image\n",
    "# def dogPixelCount(doglist):\n",
    "#   totalpixels = 0\n",
    "#   for dog in doglist:\n",
    "#     totalpixels += (dog[3] - dog[1]) * (dog[4] - dog[2])\n",
    "#   return totalpixels\n",
    "\n",
    "# # Define a UDF for the pixel count\n",
    "# udfDogPixelCount = F.udf(dogPixelCount, IntegerType())\n",
    "# joined_df = joined_df.withColumn('dog_pixels', udfDogPixelCount('dogs'))\n",
    "\n",
    "# # Create a column representing the percentage of pixels\n",
    "# joined_df = joined_df.withColumn('dog_percent', (joined_df.dog_pixels / (joined_df.width * joined_df.height)) * 100)\n",
    "\n",
    "# # Show the first 10 annotations with more than 60% dog\n",
    "# joined_df.where('dog_percent > 60').show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big-data-with-pyspark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
